{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cf01bc7",
   "metadata": {},
   "source": [
    "# Testing CIN Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1725362b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from cin_model import CIN_MODEL\n",
    "import torch\n",
    "import numpy as np  \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "cin = CIN_MODEL()\n",
    "limit=100\n",
    "msgs= [torch.randint(0,2,(1,30)) for _i in range(limit)]\n",
    "img_list='dataset/temp/0'\n",
    "imgs_model,org_imgs_model = cin._encode_(img_list,msgs,limit=limit)\n",
    "decoded_msgs = cin._decode_(imgs_model)\n",
    "\n",
    "bitacc = [np.mean((msgs[i].numpy() == decoded_msgs[i]).astype(np.float32)) for i in range(limit)]\n",
    "np.mean(bitacc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b84021",
   "metadata": {},
   "source": [
    "Confirming Published Results on Robustness and Visual Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad61f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack: Identity, Bit accuracy after attack: 1.00000 ± 0.00000\n",
      "Attack: JPEG-50, Bit accuracy after attack: 0.94667 ± 0.05812\n",
      "Attack: Gauss.Blur-2.0, Bit accuracy after attack: 0.96400 ± 0.03580\n",
      "Attack: Dropout-30%, Bit accuracy after attack: 0.98167 ± 0.04907\n",
      "Attack: Cropout-30%, Bit accuracy after attack: 1.00000 ± 0.00000\n",
      "Attack: Crop-3.5%, Bit accuracy after attack: 1.00000 ± 0.00000\n",
      "PSNR: 35.09, SSIM: 0.9276\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from utilsNew import tensor2PIL\n",
    "encode_image_pil = tensor2PIL(imgs_model)\n",
    "orig_image_pil = tensor2PIL(org_imgs_model)\n",
    "\n",
    "\n",
    "from img_attacks import *\n",
    "from torchvision import transforms\n",
    "\n",
    "attacks =  { \n",
    "            \"Identity\":[lambda x,y:x, {\"y\":None}],\n",
    "            \"JPEG-50\":[jpeg_comp, {\"quality\": 50}],\n",
    "            \"Gauss.Blur-2.0\":[gaussian_blur_pil, {\"sigma\": 2.0}],\n",
    "           \"Dropout-30%\":[apply_dropout_pil, {\"p\": 0.3}],\n",
    "            \"Cropout-30%\":[cropout_fn, {\"crop_ratio\": 0.3}],\n",
    "            \"Crop-3.5%\":[blacken_edges, {\"ratio\": 0.035}],\n",
    "}\n",
    "\n",
    "for attack in attacks.keys():\n",
    "    attacked_imgs = []\n",
    "    bit_acc_attacked =[]\n",
    "    for img in encode_image_pil:\n",
    "        attacked_img = attacks[attack][0](img, **attacks[attack][1])\n",
    "        attacked_img_ = transforms.ToTensor()(attacked_img).unsqueeze(0)  # Convert to tensor and add batch dimension\n",
    "        attacked_imgs.append(attacked_img_)\n",
    "    \n",
    "    decoded_message_attacked = cin._decode_(attacked_imgs)\n",
    "    bit_acc_attacked = [np.mean(decoded_message_attacked[i] == msgs[i].detach().cpu().numpy()) for i in range(len(decoded_message_attacked))]\n",
    "    print(f\"Attack: {attack}, Bit accuracy after attack: {np.mean(bit_acc_attacked):.5f} ± {np.std(bit_acc_attacked):.5f}\")\n",
    "\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "psnr_values = [np.mean([psnr(np.array(orig_image_pil[i]), np.array(encode_image_pil[i]),data_range=255) for i in range(len(orig_image_pil))])]\n",
    "ssim_values = [np.mean([ssim(np.array(orig_image_pil[i]), np.array(encode_image_pil[i]), channel_axis=-1, data_range=255) for i in range(len(orig_image_pil))])]\n",
    "print(f\"PSNR: {psnr_values[0]:.2f}, SSIM: {ssim_values[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf60c67b",
   "metadata": {},
   "source": [
    "Comment: Approximately mathces the publsihed results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0af626",
   "metadata": {},
   "source": [
    "# Testing WmForger Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129a5dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from videoseal.wmforger.optimize_image import get_artifact_discriminator\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "class WMFORGER_MODEL():\n",
    "    def __init__(self, device=\"cuda\", ckt_path=\"videoseal/wmforger/convnext_pref_model.pth\"):\n",
    "        self.device = device\n",
    "        self.ckt_path = ckt_path\n",
    "        self.model =  get_artifact_discriminator(ckt_path, device=self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "    @staticmethod\n",
    "    def optimize(img, model, device=\"cuda:0\", num_steps=100, lr=0.05):\n",
    "        \"\"\"\n",
    "        Optimize the image to remove the watermark by doing gradient descent.\n",
    "        The loss is minus the preference model output,\n",
    "        i.e. we maximize the preference model output.\n",
    "        \"\"\"\n",
    "        transform_image = transforms.Compose([\n",
    "            transforms.Resize((768, 768)),\n",
    "        ])\n",
    "        img = transform_image(img).to(device)\n",
    "        param = torch.nn.Parameter(torch.zeros_like(img)).to(device)\n",
    "\n",
    "        optim = torch.optim.SGD([param], lr=lr)\n",
    "        for _ in range(num_steps):\n",
    "            optim.zero_grad()\n",
    "            loss = -model((img + param).clip(0, 1)).mean()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "        return (img + param).clip(0, 1).detach().cpu()\n",
    "    @staticmethod\n",
    "    def clean_watermark(img_wm, stolen_watermark):\n",
    "        kernel_x = torch.tensor(\n",
    "                [[-1., 0., 1.],\n",
    "                [-2., 0., 2.],\n",
    "                [-1., 0., 1.]]\n",
    "            ).unsqueeze(0).unsqueeze(0)\n",
    "        kernel_y = torch.tensor(\n",
    "            [[1., 2., 1.],\n",
    "            [0., 0., 0.],\n",
    "            [-1., -2., -1.]]\n",
    "        ).unsqueeze(0).unsqueeze(0)\n",
    "        kernel_to_grayscale = torch.tensor(\n",
    "            [0.299, 0.587, 0.114]\n",
    "        ).unsqueeze(1).unsqueeze(1).unsqueeze(0)\n",
    "\n",
    "        conv_rgb = nn.Conv2d(3, 1, kernel_size=1, padding=0, bias=False)\n",
    "        conv_x = nn.Conv2d(1, 1, kernel_size=3, padding=1, bias=False, padding_mode='reflect')\n",
    "        conv_y = nn.Conv2d(1, 1, kernel_size=3, padding=1, bias=False, padding_mode='reflect')\n",
    "        conv_rgb.weight = nn.Parameter(kernel_to_grayscale, requires_grad=False)\n",
    "        conv_x.weight = nn.Parameter(kernel_x, requires_grad=False)\n",
    "        conv_y.weight = nn.Parameter(kernel_y, requires_grad=False)\n",
    "\n",
    "        x = conv_rgb(img_wm)\n",
    "        grad_x = conv_x(x)\n",
    "        grad_y = conv_y(x)\n",
    "        edge_map = grad_x.mul_(grad_x).add_(grad_y.mul_(grad_y)).clip(0,1)\n",
    "\n",
    "        # Reduce gradients in stolen watermark.\n",
    "        stolen_watermark = stolen_watermark * (1 - edge_map.sqrt())\n",
    "        return stolen_watermark\n",
    "    def remove_watermark(self,imgs,num_steps=100, lr=0.05, clean_wm=False):\n",
    "        '''\n",
    "        Remove watermark from a batch of images.\n",
    "            imgs: list of torch tensors with shape (1,3,H,W) in range [0,1]\n",
    "            num_steps: number of optimization steps\n",
    "            lr: learning rate for optimization\n",
    "        Returns:\n",
    "            cleaned_imgs: list of torch tensors with shape (1,3,H,W) in range [0,1]\n",
    "        '''\n",
    "        cleaned_imgs=[]\n",
    "        for img_wm in imgs:\n",
    "            img_wm = img_wm.to(\"cpu\")\n",
    "            img_cleaned = self.optimize(img_wm, self.model, device=self.device, num_steps=num_steps, lr=lr)\n",
    "            stolen_watermark = img_wm - F.interpolate(img_cleaned, size=img_wm.shape[-2:], mode=\"bilinear\", align_corners=True, antialias=False)\n",
    "            \n",
    "            #Optionally clean the stolen watermark \n",
    "            if clean_wm:\n",
    "                stolen_watermark = self.clean_watermark(img_wm,stolen_watermark)\n",
    "            alpha = 2.0 # strength factor for the attack\n",
    "            img_removed = img_wm - alpha * stolen_watermark\n",
    "            \n",
    "            cleaned_imgs.append(torch.clip(img_removed,0,1))\n",
    "        return cleaned_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3be71df",
   "metadata": {},
   "source": [
    "Without Cleaning the Watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53652429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#As Reported in the Paper\n",
    "\n",
    "wmforger = WMFORGER_MODEL() \n",
    "cleaned_imgs_cin= wmforger.remove_watermark(imgs_model,num_steps=500, lr=0.05,clean_wm=False)\n",
    "decoded_msgs_cleaned = cin._decode_(cleaned_imgs_cin)\n",
    "bitacc = [np.mean((msgs[i].numpy() == decoded_msgs_cleaned[i]).astype(np.float32)) for i in range(len(imgs_model))]\n",
    "np.mean(bitacc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85c4cfa",
   "metadata": {},
   "source": [
    "With Cleaninig the Watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bcf888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10333333"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_imgs_cin= wmforger.remove_watermark(imgs_model,num_steps=500, lr=0.05, clean_wm=True)\n",
    "decoded_msgs_cleaned = cin._decode_(cleaned_imgs_cin)\n",
    "bitacc = [np.mean((msgs[i].numpy() == decoded_msgs_cleaned[i]).astype(np.float32)) for i in range(len(imgs_model))]\n",
    "np.mean(bitacc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch2.0)",
   "language": "python",
   "name": "torch2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
